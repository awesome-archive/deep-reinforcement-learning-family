Learning human behaviors from motion capture by adversarial imitation

Josh Merel, Yuval Tassa, Dhruva TB, Sriram Srinivasan, Jay Lemmon, Ziyu Wang,
Greg Wayne, Nicolas Heess

> DeepMind

Rapid progress in deep reinforcement learning has made it increasingly feasible
to train controllers for high-dimensional humanoid bodies. However, methods
that use pure reinforcement learning with simple reward functions tend to produce
non-humanlike and overly stereotyped movement behaviors. In this work,
we extend generative adversarial imitation learning to enable training of generic
neural network policies to produce humanlike movement patterns from limited
demonstrations consisting only of partially observed state features, without access
to actions, even when the demonstrations come from a body with different and
unknown physical parameters. We leverage this approach to build sub-skill policies
from motion capture data and show that they can be reused to solve tasks when
controlled by a higher level controller. [video abstract]
