Imagination-Augmented Agents for Deep Reinforcement Learning

Théophane Weber∗ Sébastien Racanière∗ David P. Reichert∗ Lars Buesing
Arthur Guez Danilo Rezende Adria Puigdomènech Badia Oriol Vinyals
Nicolas Heess Yujia Li Razvan Pascanu Peter Battaglia
David Silver Daan Wierstra

We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep
reinforcement learning combining model-free and model-based aspects. In contrast
to most existing model-based reinforcement learning and planning methods,
which prescribe how a model should be used to arrive at a policy, I2As learn to
interpret predictions from a learned environment model to construct implicit plans
in arbitrary ways, by using the predictions as additional context in deep policy
networks. I2As show improved data efficiency, performance, and robustness to
model misspecification compared to several baselines.
